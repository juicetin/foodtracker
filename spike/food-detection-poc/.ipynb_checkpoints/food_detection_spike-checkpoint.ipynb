{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food Detection POC / Spike\n",
    "\n",
    "**Goal:** Validate whether traditional ML (YOLO + CNN classifiers) can produce accurate-enough ingredient detection and weight estimation for a macro-tracking app, *before* committing to a full backend implementation.\n",
    "\n",
    "## Pipeline\n",
    "1. Load image + extract EXIF metadata (camera, focal length)\n",
    "2. YOLO detection → bounding boxes + labels + confidence\n",
    "3. Dish classification → infer hidden ingredients\n",
    "4. Distance / dimension estimation from EXIF + bounding box geometry\n",
    "5. Weight estimation per ingredient\n",
    "6. Nutritional lookup (USDA FoodData Central)\n",
    "7. Summary: total macros/micros per photo\n",
    "\n",
    "## How to use\n",
    "1. Drop your food photos into `./test_images/`\n",
    "2. Run cells top-to-bottom\n",
    "3. Review detection results visually\n",
    "4. Annotate accuracy in the review section\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 0: Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once to install dependencies\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional\n",
    "\n",
    "import cv2\n",
    "import exifread\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Create test_images directory if it doesn't exist\n",
    "Path('./test_images').mkdir(exist_ok=True)\n",
    "\n",
    "print('All imports loaded. Drop food photos into ./test_images/ and continue.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Image Loading + EXIF Metadata Extraction\n",
    "\n",
    "We extract camera metadata to later estimate distance-to-subject and real-world dimensions.\n",
    "\n",
    "Key EXIF fields:\n",
    "- **FocalLength**: lens focal length in mm — used for distance estimation\n",
    "- **FocalLengthIn35mmFilm**: normalized focal length for cross-device comparison\n",
    "- **Make / Model**: camera/phone identifier\n",
    "- **ImageWidth / ImageLength**: pixel dimensions\n",
    "- **ExifImageWidth / ExifImageHeight**: actual capture resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageMetadata:\n",
    "    \"\"\"EXIF and derived metadata for a food photo.\"\"\"\n",
    "    file_path: str\n",
    "    width_px: int = 0\n",
    "    height_px: int = 0\n",
    "    camera_make: str = 'unknown'\n",
    "    camera_model: str = 'unknown'\n",
    "    focal_length_mm: Optional[float] = None\n",
    "    focal_length_35mm: Optional[float] = None\n",
    "    # Sensor size defaults — common smartphone sensor (1/1.7\")\n",
    "    sensor_width_mm: float = 7.6\n",
    "    sensor_height_mm: float = 5.7\n",
    "\n",
    "\n",
    "# Known sensor sizes for common phones (width_mm, height_mm)\n",
    "# Extend this as you test with different devices\n",
    "KNOWN_SENSORS: dict[str, tuple[float, float]] = {\n",
    "    'iPhone 15 Pro': (9.8, 7.3),       # 1/1.28\"\n",
    "    'iPhone 15 Pro Max': (9.8, 7.3),\n",
    "    'iPhone 14 Pro': (9.8, 7.3),\n",
    "    'iPhone 14 Pro Max': (9.8, 7.3),\n",
    "    'iPhone 13 Pro': (7.6, 5.7),       # 1/1.7\"\n",
    "    'iPhone 13': (7.6, 5.7),\n",
    "    'Pixel 8 Pro': (9.8, 7.3),         # 1/1.31\"\n",
    "    'Pixel 7 Pro': (9.8, 7.3),\n",
    "    'Samsung SM-S928B': (9.8, 7.3),    # S24 Ultra\n",
    "    'Samsung SM-S918B': (9.8, 7.3),    # S23 Ultra\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_focal_length(tag_value) -> Optional[float]:\n",
    "    \"\"\"Parse EXIF focal length tag to float mm value.\"\"\"\n",
    "    try:\n",
    "        val = tag_value.values[0]\n",
    "        if hasattr(val, 'num') and hasattr(val, 'den'):\n",
    "            return float(val.num) / float(val.den)\n",
    "        return float(val)\n",
    "    except (IndexError, TypeError, ZeroDivisionError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_metadata(image_path: str) -> ImageMetadata:\n",
    "    \"\"\"Extract EXIF metadata from image file.\"\"\"\n",
    "    meta = ImageMetadata(file_path=image_path)\n",
    "\n",
    "    # Get pixel dimensions from PIL (reliable even without EXIF)\n",
    "    with Image.open(image_path) as img:\n",
    "        meta.width_px, meta.height_px = img.size\n",
    "\n",
    "    # Extract EXIF tags\n",
    "    with open(image_path, 'rb') as f:\n",
    "        tags = exifread.process_file(f, details=False)\n",
    "\n",
    "    if not tags:\n",
    "        print(f'  Warning: No EXIF data found in {image_path}')\n",
    "        return meta\n",
    "\n",
    "    meta.camera_make = str(tags.get('Image Make', 'unknown')).strip()\n",
    "    meta.camera_model = str(tags.get('Image Model', 'unknown')).strip()\n",
    "\n",
    "    if 'EXIF FocalLength' in tags:\n",
    "        meta.focal_length_mm = _parse_focal_length(tags['EXIF FocalLength'])\n",
    "\n",
    "    if 'EXIF FocalLengthIn35mmFilm' in tags:\n",
    "        try:\n",
    "            meta.focal_length_35mm = float(tags['EXIF FocalLengthIn35mmFilm'].values[0])\n",
    "        except (IndexError, TypeError):\n",
    "            pass\n",
    "\n",
    "    # Look up sensor size from known devices\n",
    "    for model_name, (sw, sh) in KNOWN_SENSORS.items():\n",
    "        if model_name.lower() in meta.camera_model.lower():\n",
    "            meta.sensor_width_mm = sw\n",
    "            meta.sensor_height_mm = sh\n",
    "            break\n",
    "\n",
    "    return meta\n",
    "\n",
    "\n",
    "# --- Load all test images ---\n",
    "IMAGE_DIR = Path('./test_images')\n",
    "image_extensions = {'.jpg', '.jpeg', '.png', '.heic', '.webp'}\n",
    "image_paths = sorted(\n",
    "    p for p in IMAGE_DIR.iterdir()\n",
    "    if p.suffix.lower() in image_extensions\n",
    ")\n",
    "\n",
    "if not image_paths:\n",
    "    print('No images found in ./test_images/')\n",
    "    print('Please add some food photos and re-run this cell.')\n",
    "else:\n",
    "    print(f'Found {len(image_paths)} image(s):')\n",
    "    all_metadata = {}\n",
    "    for p in image_paths:\n",
    "        meta = extract_metadata(str(p))\n",
    "        all_metadata[p.name] = meta\n",
    "        print(f'  {p.name}: {meta.width_px}x{meta.height_px}, '\n",
    "              f'camera={meta.camera_model}, focal={meta.focal_length_mm}mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: YOLO Food Detection\n",
    "\n",
    "We start with the pretrained YOLOv8n (nano) model on COCO. This knows ~80 object classes including some foods (banana, apple, pizza, cake, sandwich, etc.).\n",
    "\n",
    "**Limitation:** COCO only has ~10 food classes. For a production tracker we'd fine-tune on Food-101 or ISIA Food-500. This cell validates the *pipeline* — accuracy will improve with a food-specific model.\n",
    "\n",
    "### What to look for during review\n",
    "- Does it draw boxes around food items (vs non-food)?\n",
    "- Are the bounding boxes tight or sloppy?\n",
    "- What confidence scores do correct detections get?\n",
    "- What foods does it miss entirely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO model — downloads weights on first run (~6MB for nano)\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "# COCO classes that are food-related (for filtering)\n",
    "COCO_FOOD_CLASSES = {\n",
    "    46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange',\n",
    "    50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza',\n",
    "    54: 'donut', 55: 'cake',\n",
    "    # Also useful context:\n",
    "    39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork',\n",
    "    43: 'knife', 44: 'spoon', 45: 'bowl',\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Detection:\n",
    "    \"\"\"A single detected object in the image.\"\"\"\n",
    "    label: str\n",
    "    confidence: float\n",
    "    bbox_xyxy: list[float]   # [x1, y1, x2, y2] in pixels\n",
    "    class_id: int\n",
    "    is_food: bool = False\n",
    "\n",
    "    @property\n",
    "    def bbox_width_px(self) -> float:\n",
    "        return self.bbox_xyxy[2] - self.bbox_xyxy[0]\n",
    "\n",
    "    @property\n",
    "    def bbox_height_px(self) -> float:\n",
    "        return self.bbox_xyxy[3] - self.bbox_xyxy[1]\n",
    "\n",
    "    @property\n",
    "    def bbox_area_px(self) -> float:\n",
    "        return self.bbox_width_px * self.bbox_height_px\n",
    "\n",
    "\n",
    "def detect_food(image_path: str, conf_threshold: float = 0.25) -> list[Detection]:\n",
    "    \"\"\"Run YOLO detection and return structured results.\"\"\"\n",
    "    results = yolo_model.predict(source=image_path, conf=conf_threshold, verbose=False)\n",
    "    detections = []\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls[0])\n",
    "            label = yolo_model.names[class_id]\n",
    "            det = Detection(\n",
    "                label=label,\n",
    "                confidence=float(box.conf[0]),\n",
    "                bbox_xyxy=box.xyxy[0].tolist(),\n",
    "                class_id=class_id,\n",
    "                is_food=class_id in COCO_FOOD_CLASSES,\n",
    "            )\n",
    "            detections.append(det)\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "def visualise_detections(image_path: str, detections: list[Detection]):\n",
    "    \"\"\"Display image with bounding boxes overlaid.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.imshow(img)\n",
    "\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2 = det.bbox_xyxy\n",
    "        color = 'lime' if det.is_food else 'cyan'\n",
    "        rect = patches.Rectangle(\n",
    "            (x1, y1), x2 - x1, y2 - y1,\n",
    "            linewidth=2, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(\n",
    "            x1, y1 - 5,\n",
    "            f'{det.label} ({det.confidence:.0%})',\n",
    "            color='white', fontsize=9,\n",
    "            bbox=dict(boxstyle='round,pad=0.2', facecolor=color, alpha=0.7)\n",
    "        )\n",
    "\n",
    "    food_count = sum(1 for d in detections if d.is_food)\n",
    "    ax.set_title(f'{Path(image_path).name} — {food_count} food items, '\n",
    "                 f'{len(detections)} total detections')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Run detection on all test images ---\n",
    "all_detections: dict[str, list[Detection]] = {}\n",
    "\n",
    "for img_path in image_paths:\n",
    "    dets = detect_food(str(img_path))\n",
    "    all_detections[img_path.name] = dets\n",
    "    visualise_detections(str(img_path), dets)\n",
    "\n",
    "    food_dets = [d for d in dets if d.is_food]\n",
    "    print(f'  Food items: {[f\"{d.label} ({d.confidence:.0%})\" for d in food_dets]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Dish Classification (Infer Hidden Ingredients)\n",
    "\n",
    "YOLO tells us *what objects are visible*. But a photo of \"fried rice\" contains soy sauce, oil, egg, etc. that aren't individually detectable.\n",
    "\n",
    "We use a separate classifier to identify the *dish* and then look up its typical ingredient composition.\n",
    "\n",
    "**Approach for this spike:** We use a simple lookup table mapping dish names → expected ingredients. In production this could be:\n",
    "- A Food-101 fine-tuned classifier (EfficientNet or MobileViT)\n",
    "- An LLM fallback for unusual dishes\n",
    "- A user-editable recipe database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dish → typical ingredients mapping\n",
    "# This is a stand-in for a trained classifier. In production you'd use\n",
    "# a Food-101 model to classify the dish, then look up ingredients.\n",
    "DISH_INGREDIENTS: dict[str, list[dict]] = {\n",
    "    'pizza': [\n",
    "        {'name': 'pizza dough', 'weight_pct': 0.35},\n",
    "        {'name': 'mozzarella cheese', 'weight_pct': 0.25},\n",
    "        {'name': 'tomato sauce', 'weight_pct': 0.15},\n",
    "        {'name': 'olive oil', 'weight_pct': 0.05},\n",
    "    ],\n",
    "    'sandwich': [\n",
    "        {'name': 'bread', 'weight_pct': 0.30},\n",
    "        {'name': 'deli meat', 'weight_pct': 0.25},\n",
    "        {'name': 'cheese', 'weight_pct': 0.15},\n",
    "        {'name': 'lettuce', 'weight_pct': 0.10},\n",
    "        {'name': 'tomato', 'weight_pct': 0.05},\n",
    "        {'name': 'mayonnaise', 'weight_pct': 0.05},\n",
    "    ],\n",
    "    'cake': [\n",
    "        {'name': 'flour', 'weight_pct': 0.25},\n",
    "        {'name': 'sugar', 'weight_pct': 0.20},\n",
    "        {'name': 'butter', 'weight_pct': 0.15},\n",
    "        {'name': 'eggs', 'weight_pct': 0.15},\n",
    "        {'name': 'frosting', 'weight_pct': 0.20},\n",
    "    ],\n",
    "    'hot dog': [\n",
    "        {'name': 'hot dog sausage', 'weight_pct': 0.45},\n",
    "        {'name': 'hot dog bun', 'weight_pct': 0.35},\n",
    "        {'name': 'ketchup', 'weight_pct': 0.10},\n",
    "        {'name': 'mustard', 'weight_pct': 0.05},\n",
    "    ],\n",
    "    # Fruits and vegetables are typically \"what you see is what you get\"\n",
    "    'banana': [{'name': 'banana', 'weight_pct': 1.0}],\n",
    "    'apple': [{'name': 'apple', 'weight_pct': 1.0}],\n",
    "    'orange': [{'name': 'orange', 'weight_pct': 1.0}],\n",
    "    'broccoli': [{'name': 'broccoli', 'weight_pct': 1.0}],\n",
    "    'carrot': [{'name': 'carrot', 'weight_pct': 1.0}],\n",
    "    'donut': [\n",
    "        {'name': 'flour', 'weight_pct': 0.30},\n",
    "        {'name': 'sugar', 'weight_pct': 0.20},\n",
    "        {'name': 'vegetable oil', 'weight_pct': 0.20},\n",
    "        {'name': 'eggs', 'weight_pct': 0.10},\n",
    "        {'name': 'glaze', 'weight_pct': 0.15},\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IngredientEstimate:\n",
    "    \"\"\"An estimated ingredient with source attribution.\"\"\"\n",
    "    name: str\n",
    "    source: str           # 'detected' or 'inferred_from_dish'\n",
    "    weight_pct: float     # proportion of total dish weight\n",
    "    weight_g: float = 0.0 # filled in by weight estimation step\n",
    "\n",
    "\n",
    "def infer_ingredients(detections: list[Detection]) -> list[IngredientEstimate]:\n",
    "    \"\"\"Combine YOLO detections with dish-level ingredient inference.\"\"\"\n",
    "    ingredients = []\n",
    "    seen_labels = set()\n",
    "\n",
    "    for det in detections:\n",
    "        if not det.is_food:\n",
    "            continue\n",
    "\n",
    "        label = det.label\n",
    "        if label in seen_labels:\n",
    "            continue\n",
    "        seen_labels.add(label)\n",
    "\n",
    "        # Look up dish ingredients\n",
    "        if label in DISH_INGREDIENTS:\n",
    "            for ing in DISH_INGREDIENTS[label]:\n",
    "                source = 'detected' if ing['name'] == label else 'inferred_from_dish'\n",
    "                ingredients.append(IngredientEstimate(\n",
    "                    name=ing['name'],\n",
    "                    source=source,\n",
    "                    weight_pct=ing['weight_pct'],\n",
    "                ))\n",
    "        else:\n",
    "            # Unknown dish — treat the detection label as a single ingredient\n",
    "            ingredients.append(IngredientEstimate(\n",
    "                name=label,\n",
    "                source='detected',\n",
    "                weight_pct=1.0,\n",
    "            ))\n",
    "\n",
    "    return ingredients\n",
    "\n",
    "\n",
    "# --- Run ingredient inference ---\n",
    "all_ingredients: dict[str, list[IngredientEstimate]] = {}\n",
    "\n",
    "for img_name, dets in all_detections.items():\n",
    "    ings = infer_ingredients(dets)\n",
    "    all_ingredients[img_name] = ings\n",
    "\n",
    "    print(f'\\n{img_name}:')\n",
    "    if ings:\n",
    "        for ing in ings:\n",
    "            print(f'  [{ing.source:>20}] {ing.name} ({ing.weight_pct:.0%})')\n",
    "    else:\n",
    "        print('  No food items detected — try a different photo or lower conf_threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Distance & Dimension Estimation\n",
    "\n",
    "Using EXIF focal length + known sensor size + assumptions about plate/bowl diameter, we estimate how far the camera was from the food, and convert bounding box pixels into real-world centimetres.\n",
    "\n",
    "### The geometry\n",
    "```\n",
    "real_width = (object_px / image_px) * (sensor_width_mm / focal_length_mm) * distance_mm\n",
    "```\n",
    "\n",
    "Since we don't know `distance_mm` directly, we use a **reference object** — typically the plate/bowl detected by YOLO. Standard dinner plate ≈ 26cm diameter.\n",
    "\n",
    "If no reference object is found, we fall back to a \"typical overhead phone photo\" distance of ~30cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference object sizes (real-world diameter in cm)\n",
    "REFERENCE_SIZES_CM: dict[str, float] = {\n",
    "    'bowl': 18.0,        # standard cereal/soup bowl\n",
    "    'cup': 8.0,          # standard mug diameter\n",
    "    'wine glass': 8.0,\n",
    "    'fork': 19.0,        # length\n",
    "    'knife': 22.0,       # length\n",
    "    'spoon': 17.0,       # length\n",
    "    'bottle': 7.0,       # diameter\n",
    "}\n",
    "\n",
    "DEFAULT_PLATE_DIAMETER_CM = 26.0\n",
    "DEFAULT_DISTANCE_CM = 30.0  # typical overhead phone shot distance\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SceneGeometry:\n",
    "    \"\"\"Estimated real-world geometry of the scene.\"\"\"\n",
    "    px_per_cm: float         # pixels per centimetre\n",
    "    distance_cm: float       # estimated camera-to-food distance\n",
    "    reference_used: str      # what object was used for calibration\n",
    "    confidence: str          # 'high', 'medium', 'low'\n",
    "\n",
    "\n",
    "def estimate_scene_geometry(\n",
    "    metadata: ImageMetadata,\n",
    "    detections: list[Detection],\n",
    ") -> SceneGeometry:\n",
    "    \"\"\"Estimate px/cm ratio using reference objects or fallback.\"\"\"\n",
    "\n",
    "    # Strategy 1: Use a detected reference object\n",
    "    for det in detections:\n",
    "        if det.label in REFERENCE_SIZES_CM:\n",
    "            real_size_cm = REFERENCE_SIZES_CM[det.label]\n",
    "            # Use the larger bbox dimension as the reference measurement\n",
    "            ref_px = max(det.bbox_width_px, det.bbox_height_px)\n",
    "            px_per_cm = ref_px / real_size_cm\n",
    "\n",
    "            # Back-calculate distance if we have focal length\n",
    "            distance_cm = DEFAULT_DISTANCE_CM\n",
    "            if metadata.focal_length_mm and metadata.sensor_width_mm:\n",
    "                distance_cm = (\n",
    "                    real_size_cm * 10  # to mm\n",
    "                    * metadata.focal_length_mm\n",
    "                    / (ref_px / metadata.width_px * metadata.sensor_width_mm)\n",
    "                ) / 10  # back to cm\n",
    "\n",
    "            return SceneGeometry(\n",
    "                px_per_cm=px_per_cm,\n",
    "                distance_cm=distance_cm,\n",
    "                reference_used=det.label,\n",
    "                confidence='medium',\n",
    "            )\n",
    "\n",
    "    # Strategy 2: Assume largest food bounding box is on a standard plate\n",
    "    food_dets = [d for d in detections if d.is_food]\n",
    "    if food_dets:\n",
    "        largest = max(food_dets, key=lambda d: d.bbox_area_px)\n",
    "        # Assume the food fills ~70% of a standard plate\n",
    "        estimated_plate_px = max(largest.bbox_width_px, largest.bbox_height_px) / 0.7\n",
    "        px_per_cm = estimated_plate_px / DEFAULT_PLATE_DIAMETER_CM\n",
    "\n",
    "        return SceneGeometry(\n",
    "            px_per_cm=px_per_cm,\n",
    "            distance_cm=DEFAULT_DISTANCE_CM,\n",
    "            reference_used='assumed_plate',\n",
    "            confidence='low',\n",
    "        )\n",
    "\n",
    "    # Strategy 3: Pure fallback — use image width as ~30cm field of view\n",
    "    return SceneGeometry(\n",
    "        px_per_cm=metadata.width_px / 30.0,\n",
    "        distance_cm=DEFAULT_DISTANCE_CM,\n",
    "        reference_used='fallback',\n",
    "        confidence='low',\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Estimate geometry for each image ---\n",
    "all_geometry: dict[str, SceneGeometry] = {}\n",
    "\n",
    "for img_name in all_detections:\n",
    "    meta = all_metadata[img_name]\n",
    "    dets = all_detections[img_name]\n",
    "    geo = estimate_scene_geometry(meta, dets)\n",
    "    all_geometry[img_name] = geo\n",
    "\n",
    "    print(f'{img_name}:')\n",
    "    print(f'  px/cm = {geo.px_per_cm:.1f}, distance = {geo.distance_cm:.0f}cm, '\n",
    "          f'ref = {geo.reference_used}, confidence = {geo.confidence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Weight Estimation\n",
    "\n",
    "Now we combine:\n",
    "- Bounding box size (from YOLO)\n",
    "- Scene geometry (px → cm conversion)\n",
    "- Food density lookup table\n",
    "- Dish ingredient proportions\n",
    "\n",
    "to estimate the weight in grams for each ingredient.\n",
    "\n",
    "### Simplifying assumptions for this spike\n",
    "- Food item depth ≈ 50% of the smaller bbox dimension (overhead view)\n",
    "- Volume modelled as an ellipsoid: `V = (4/3) * π * (w/2) * (h/2) * (d/2)`\n",
    "- Default density = 0.8 g/cm³ (roughly cooked food average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Food density table — replicating the one from the backend config\n",
    "FOOD_DENSITY: dict[str, float] = {\n",
    "    # Proteins\n",
    "    'chicken breast': 1.04, 'deli meat': 1.04, 'beef': 1.05,\n",
    "    'salmon': 1.02, 'egg': 1.03, 'eggs': 1.03, 'tofu': 0.95,\n",
    "    'hot dog sausage': 1.02,\n",
    "    # Carbs\n",
    "    'rice': 0.81, 'pasta': 1.00, 'bread': 0.27,\n",
    "    'pizza dough': 0.70, 'hot dog bun': 0.30,\n",
    "    'flour': 0.59, 'potato': 1.08, 'oats': 0.84,\n",
    "    # Vegetables\n",
    "    'broccoli': 0.35, 'carrot': 0.64, 'tomato': 0.62,\n",
    "    'lettuce': 0.36, 'cucumber': 0.96,\n",
    "    # Fruits\n",
    "    'apple': 0.64, 'banana': 0.94, 'orange': 0.87,\n",
    "    'avocado': 0.92, 'berries': 0.65,\n",
    "    # Dairy / Fats\n",
    "    'mozzarella cheese': 1.00, 'cheese': 1.00,\n",
    "    'butter': 0.91, 'olive oil': 0.91, 'vegetable oil': 0.91,\n",
    "    'mayonnaise': 0.91,\n",
    "    # Sauces\n",
    "    'tomato sauce': 1.03, 'ketchup': 1.10, 'mustard': 1.05,\n",
    "    # Sweets\n",
    "    'sugar': 0.85, 'frosting': 1.10, 'glaze': 1.15,\n",
    "}\n",
    "\n",
    "DEFAULT_DENSITY = 0.80  # g/cm³\n",
    "DEPTH_RATIO = 0.5       # assumed depth = 50% of smaller bbox dimension\n",
    "\n",
    "\n",
    "def estimate_weight(\n",
    "    detection: Detection,\n",
    "    ingredients: list[IngredientEstimate],\n",
    "    geometry: SceneGeometry,\n",
    ") -> list[IngredientEstimate]:\n",
    "    \"\"\"Estimate weight in grams for each ingredient of a detected food item.\"\"\"\n",
    "    # Convert bbox to real-world cm\n",
    "    width_cm = detection.bbox_width_px / geometry.px_per_cm\n",
    "    height_cm = detection.bbox_height_px / geometry.px_per_cm\n",
    "    depth_cm = min(width_cm, height_cm) * DEPTH_RATIO\n",
    "\n",
    "    # Ellipsoid volume\n",
    "    volume_cm3 = (4 / 3) * math.pi * (width_cm / 2) * (height_cm / 2) * (depth_cm / 2)\n",
    "\n",
    "    # Use the detection label's density, or default\n",
    "    overall_density = FOOD_DENSITY.get(detection.label, DEFAULT_DENSITY)\n",
    "    total_weight_g = volume_cm3 * overall_density\n",
    "\n",
    "    # Distribute weight across ingredients by their proportions\n",
    "    for ing in ingredients:\n",
    "        ing.weight_g = total_weight_g * ing.weight_pct\n",
    "\n",
    "    return ingredients\n",
    "\n",
    "\n",
    "# --- Estimate weights for all images ---\n",
    "for img_name in all_detections:\n",
    "    geo = all_geometry[img_name]\n",
    "    food_dets = [d for d in all_detections[img_name] if d.is_food]\n",
    "    ings = all_ingredients[img_name]\n",
    "\n",
    "    print(f'\\n{img_name} (scene: {geo.px_per_cm:.1f} px/cm, ref={geo.reference_used}):')\n",
    "\n",
    "    if not food_dets:\n",
    "        print('  No food detections.')\n",
    "        continue\n",
    "\n",
    "    for det in food_dets:\n",
    "        # Get ingredients that belong to this detection\n",
    "        det_ings = [i for i in ings]\n",
    "        estimate_weight(det, det_ings, geo)\n",
    "\n",
    "        width_cm = det.bbox_width_px / geo.px_per_cm\n",
    "        height_cm = det.bbox_height_px / geo.px_per_cm\n",
    "        total_g = sum(i.weight_g for i in det_ings)\n",
    "\n",
    "        print(f'  {det.label} ({det.confidence:.0%}): '\n",
    "              f'bbox={width_cm:.1f}x{height_cm:.1f}cm, '\n",
    "              f'estimated total={total_g:.0f}g')\n",
    "        for ing in det_ings:\n",
    "            density = FOOD_DENSITY.get(ing.name, DEFAULT_DENSITY)\n",
    "            print(f'    {ing.name}: {ing.weight_g:.0f}g '\n",
    "                  f'(density={density}, pct={ing.weight_pct:.0%})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Nutritional Lookup (USDA FoodData Central)\n",
    "\n",
    "We query the USDA FoodData Central API to get per-100g nutritional data, then scale by our estimated weights.\n",
    "\n",
    "**API:** https://api.nal.usda.gov/fdc/v1  \n",
    "**Rate limit:** 1000 requests/hour with a free API key  \n",
    "**Key nutrients:** calories (kcal), protein (g), total fat (g), carbohydrates (g), fiber (g)\n",
    "\n",
    "Get a free API key at: https://fdc.nal.usda.gov/api-key-signup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Get a free key from https://fdc.nal.usda.gov/api-key-signup\n",
    "USDA_API_KEY = os.environ.get('USDA_API_KEY', 'DEMO_KEY')\n",
    "USDA_BASE_URL = 'https://api.nal.usda.gov/fdc/v1'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NutritionPer100g:\n",
    "    \"\"\"Nutritional values per 100g of a food item.\"\"\"\n",
    "    food_name: str\n",
    "    fdc_id: int = 0\n",
    "    calories_kcal: float = 0.0\n",
    "    protein_g: float = 0.0\n",
    "    fat_g: float = 0.0\n",
    "    carbs_g: float = 0.0\n",
    "    fiber_g: float = 0.0\n",
    "    source: str = 'usda'\n",
    "\n",
    "\n",
    "# Local cache to avoid repeat API calls within the notebook session\n",
    "_nutrition_cache: dict[str, NutritionPer100g] = {}\n",
    "\n",
    "# Nutrient ID mapping for USDA FoodData Central\n",
    "NUTRIENT_IDS = {\n",
    "    1008: 'calories_kcal',  # Energy\n",
    "    1003: 'protein_g',      # Protein\n",
    "    1004: 'fat_g',          # Total lipid (fat)\n",
    "    1005: 'carbs_g',        # Carbohydrate, by difference\n",
    "    1079: 'fiber_g',        # Fiber, total dietary\n",
    "}\n",
    "\n",
    "\n",
    "def lookup_nutrition(food_name: str) -> NutritionPer100g:\n",
    "    \"\"\"Search USDA FoodData Central for nutritional info.\"\"\"\n",
    "    if food_name in _nutrition_cache:\n",
    "        return _nutrition_cache[food_name]\n",
    "\n",
    "    result = NutritionPer100g(food_name=food_name)\n",
    "\n",
    "    try:\n",
    "        # Search for the food\n",
    "        resp = requests.get(\n",
    "            f'{USDA_BASE_URL}/foods/search',\n",
    "            params={\n",
    "                'api_key': USDA_API_KEY,\n",
    "                'query': food_name,\n",
    "                'pageSize': 1,\n",
    "                'dataType': 'Foundation,SR Legacy',\n",
    "            },\n",
    "            timeout=10,\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        if not data.get('foods'):\n",
    "            print(f'  USDA: No results for \"{food_name}\"')\n",
    "            _nutrition_cache[food_name] = result\n",
    "            return result\n",
    "\n",
    "        food = data['foods'][0]\n",
    "        result.fdc_id = food.get('fdcId', 0)\n",
    "        result.food_name = food.get('description', food_name)\n",
    "\n",
    "        for nutrient in food.get('foodNutrients', []):\n",
    "            nid = nutrient.get('nutrientId')\n",
    "            if nid in NUTRIENT_IDS:\n",
    "                setattr(result, NUTRIENT_IDS[nid], nutrient.get('value', 0.0))\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f'  USDA API error for \"{food_name}\": {e}')\n",
    "\n",
    "    _nutrition_cache[food_name] = result\n",
    "    return result\n",
    "\n",
    "\n",
    "# --- Look up nutrition for all detected ingredients ---\n",
    "all_nutrition: dict[str, NutritionPer100g] = {}\n",
    "\n",
    "for img_name, ings in all_ingredients.items():\n",
    "    print(f'\\nLooking up nutrition for {img_name}...')\n",
    "    for ing in ings:\n",
    "        if ing.name not in all_nutrition:\n",
    "            nutr = lookup_nutrition(ing.name)\n",
    "            all_nutrition[ing.name] = nutr\n",
    "            print(f'  {ing.name} → {nutr.food_name} '\n",
    "                  f'({nutr.calories_kcal:.0f} kcal/100g, '\n",
    "                  f'P:{nutr.protein_g:.1f}g, F:{nutr.fat_g:.1f}g, '\n",
    "                  f'C:{nutr.carbs_g:.1f}g)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Summary — Total Macros Per Photo\n",
    "\n",
    "Combine estimated weights + nutritional data → final calorie/macro breakdown per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MealSummary:\n",
    "    \"\"\"Total nutritional summary for one image.\"\"\"\n",
    "    image_name: str\n",
    "    total_calories: float = 0.0\n",
    "    total_protein_g: float = 0.0\n",
    "    total_fat_g: float = 0.0\n",
    "    total_carbs_g: float = 0.0\n",
    "    total_fiber_g: float = 0.0\n",
    "    total_weight_g: float = 0.0\n",
    "    ingredient_details: list = field(default_factory=list)\n",
    "\n",
    "\n",
    "def compute_meal_summary(\n",
    "    img_name: str,\n",
    "    ingredients: list[IngredientEstimate],\n",
    "    nutrition_db: dict[str, NutritionPer100g],\n",
    ") -> MealSummary:\n",
    "    \"\"\"Calculate total nutrition for a meal image.\"\"\"\n",
    "    summary = MealSummary(image_name=img_name)\n",
    "\n",
    "    for ing in ingredients:\n",
    "        nutr = nutrition_db.get(ing.name)\n",
    "        if not nutr:\n",
    "            continue\n",
    "\n",
    "        # Scale from per-100g to actual estimated weight\n",
    "        scale = ing.weight_g / 100.0\n",
    "\n",
    "        cal = nutr.calories_kcal * scale\n",
    "        pro = nutr.protein_g * scale\n",
    "        fat = nutr.fat_g * scale\n",
    "        carb = nutr.carbs_g * scale\n",
    "        fib = nutr.fiber_g * scale\n",
    "\n",
    "        summary.total_calories += cal\n",
    "        summary.total_protein_g += pro\n",
    "        summary.total_fat_g += fat\n",
    "        summary.total_carbs_g += carb\n",
    "        summary.total_fiber_g += fib\n",
    "        summary.total_weight_g += ing.weight_g\n",
    "\n",
    "        summary.ingredient_details.append({\n",
    "            'ingredient': ing.name,\n",
    "            'source': ing.source,\n",
    "            'weight_g': round(ing.weight_g, 1),\n",
    "            'calories': round(cal, 1),\n",
    "            'protein_g': round(pro, 1),\n",
    "            'fat_g': round(fat, 1),\n",
    "            'carbs_g': round(carb, 1),\n",
    "        })\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# --- Compute summaries ---\n",
    "meal_summaries: dict[str, MealSummary] = {}\n",
    "\n",
    "for img_name, ings in all_ingredients.items():\n",
    "    summary = compute_meal_summary(img_name, ings, all_nutrition)\n",
    "    meal_summaries[img_name] = summary\n",
    "\n",
    "    print(f'\\n{\"=\" * 60}')\n",
    "    print(f'{img_name}')\n",
    "    print(f'{\"=\" * 60}')\n",
    "\n",
    "    # Ingredient breakdown table\n",
    "    if summary.ingredient_details:\n",
    "        df = pd.DataFrame(summary.ingredient_details)\n",
    "        display(df)\n",
    "\n",
    "    print(f'\\n  TOTALS:')\n",
    "    print(f'    Weight:   {summary.total_weight_g:.0f}g')\n",
    "    print(f'    Calories: {summary.total_calories:.0f} kcal')\n",
    "    print(f'    Protein:  {summary.total_protein_g:.1f}g')\n",
    "    print(f'    Fat:      {summary.total_fat_g:.1f}g')\n",
    "    print(f'    Carbs:    {summary.total_carbs_g:.1f}g')\n",
    "    print(f'    Fiber:    {summary.total_fiber_g:.1f}g')\n",
    "\n",
    "    # Geometry context\n",
    "    geo = all_geometry.get(img_name)\n",
    "    if geo:\n",
    "        print(f'\\n  Scene calibration: {geo.reference_used} '\n",
    "              f'(confidence: {geo.confidence})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Human Review & Accuracy Annotation\n",
    "\n",
    "This is the most important cell for the spike. Review the results above and annotate:\n",
    "- Was each food item correctly detected?\n",
    "- Were the inferred ingredients reasonable?\n",
    "- How close are the weight estimates to reality? (weigh your food if possible!)\n",
    "- How close are the calorie estimates?\n",
    "\n",
    "This builds a ground truth dataset that will guide decisions on:\n",
    "1. Whether YOLO alone is sufficient or we need an LLM fallback\n",
    "2. Whether the volumetric weight estimation is usable\n",
    "3. Which food categories need the most improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReviewEntry:\n",
    "    \"\"\"Human review of one image's detection results.\"\"\"\n",
    "    image_name: str\n",
    "    # What foods were actually in the photo?\n",
    "    actual_foods: list[str] = field(default_factory=list)\n",
    "    # Did the model correctly identify the foods?\n",
    "    detection_correct: bool = False\n",
    "    # Were there foods the model missed?\n",
    "    missed_foods: list[str] = field(default_factory=list)\n",
    "    # Were there false positives (things detected that aren't food)?\n",
    "    false_positives: list[str] = field(default_factory=list)\n",
    "    # Actual weight if known (e.g. you weighed the food)\n",
    "    actual_weight_g: Optional[float] = None\n",
    "    # Actual calories if known\n",
    "    actual_calories: Optional[float] = None\n",
    "    # Free-form notes\n",
    "    notes: str = ''\n",
    "\n",
    "\n",
    "# --- Fill in your reviews here ---\n",
    "# Uncomment and modify for each test image:\n",
    "\n",
    "reviews: list[ReviewEntry] = [\n",
    "    # ReviewEntry(\n",
    "    #     image_name='lunch.jpg',\n",
    "    #     actual_foods=['grilled chicken', 'white rice', 'steamed broccoli'],\n",
    "    #     detection_correct=False,\n",
    "    #     missed_foods=['rice', 'chicken'],\n",
    "    #     false_positives=[],\n",
    "    #     actual_weight_g=450,\n",
    "    #     actual_calories=520,\n",
    "    #     notes='YOLO only detected broccoli. Need food-specific model.'\n",
    "    # ),\n",
    "]\n",
    "\n",
    "\n",
    "# --- Save reviews to JSON for later analysis ---\n",
    "def save_reviews(reviews: list[ReviewEntry], path: str = './review_results.json'):\n",
    "    data = [asdict(r) for r in reviews]\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f'Saved {len(reviews)} review(s) to {path}')\n",
    "\n",
    "\n",
    "if reviews:\n",
    "    save_reviews(reviews)\n",
    "\n",
    "    # Quick accuracy summary\n",
    "    correct = sum(1 for r in reviews if r.detection_correct)\n",
    "    print(f'\\nDetection accuracy: {correct}/{len(reviews)} '\n",
    "          f'({correct/len(reviews):.0%})')\n",
    "\n",
    "    weight_errors = [\n",
    "        abs(meal_summaries[r.image_name].total_weight_g - r.actual_weight_g)\n",
    "        / r.actual_weight_g\n",
    "        for r in reviews\n",
    "        if r.actual_weight_g and r.image_name in meal_summaries\n",
    "    ]\n",
    "    if weight_errors:\n",
    "        print(f'Weight estimation mean error: {np.mean(weight_errors):.0%}')\n",
    "\n",
    "    cal_errors = [\n",
    "        abs(meal_summaries[r.image_name].total_calories - r.actual_calories)\n",
    "        / r.actual_calories\n",
    "        for r in reviews\n",
    "        if r.actual_calories and r.image_name in meal_summaries\n",
    "    ]\n",
    "    if cal_errors:\n",
    "        print(f'Calorie estimation mean error: {np.mean(cal_errors):.0%}')\n",
    "else:\n",
    "    print('No reviews yet. Fill in the reviews list above after running the pipeline.')\n",
    "    print('Tip: Weigh your food on a kitchen scale for ground truth comparison.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Based on your review results, decide:\n",
    "\n",
    "1. **If YOLO COCO detection is too limited** → Fine-tune YOLOv8 on Food-101 or ISIA Food-500 (see ADR-003)\n",
    "2. **If dish classification is needed** → Train an EfficientNet classifier on Food-101\n",
    "3. **If weight estimation is too inaccurate** → Consider requiring a reference object (coin, credit card) in photos\n",
    "4. **If the pipeline works well enough** → Port inference to Go via ONNX runtime (see ADR-002)\n",
    "\n",
    "See `docs/adr/` for architectural decision records."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
