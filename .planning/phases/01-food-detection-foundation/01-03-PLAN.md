---
phase: 01-food-detection-foundation
plan: 03
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - training/train_binary.py
  - training/train_detect.py
  - training/train_classify.py
  - training/evaluate/eval_detection.py
  - training/evaluate/eval_classification.py
autonomous: true

must_haves:
  truths:
    - "Binary food/not-food classifier achieves >90% accuracy on held-out test set"
    - "Detection model produces bounding boxes around food items with >60% mAP@0.5 on validation set"
    - "Classification model achieves >70% Top-1 accuracy on held-out test set"
    - "Per-cuisine evaluation shows accuracy breakdown for Western, Chinese, Japanese, Korean, Vietnamese, Thai"
    - "Three trained model checkpoint files exist (binary .pt, detection .pt, classification .pt)"
  artifacts:
    - path: "training/train_binary.py"
      provides: "YOLO26-N-cls binary food/not-food training script"
    - path: "training/train_detect.py"
      provides: "YOLO26-N detection training script for food bounding boxes"
    - path: "training/train_classify.py"
      provides: "YOLO26-N-cls dish classification training script"
    - path: "training/evaluate/eval_detection.py"
      provides: "Detection evaluation with per-cuisine mAP breakdown"
    - path: "training/evaluate/eval_classification.py"
      provides: "Classification evaluation with per-cuisine Top-1/Top-5 accuracy"
  key_links:
    - from: "training/train_detect.py"
      to: "training/configs/food-detect.yaml"
      via: "data parameter in model.train()"
      pattern: "model\\.train.*data.*food-detect"
    - from: "training/evaluate/eval_detection.py"
      to: "training/datasets/scripts/audit_cuisines.py"
      via: "Uses same cuisine mapping for per-cuisine breakdown"
      pattern: "cuisine.*map"
---

<objective>
Train three YOLO26 models (binary food/not-food classifier, food object detector, dish classifier) on the prepared datasets, and evaluate accuracy with per-cuisine breakdowns to identify any cuisine gaps.

Purpose: These models form the core three-stage detection pipeline: (1) binary gate filters non-food images fast, (2) detector localizes food items with bounding boxes, (3) classifier identifies specific dishes for ingredient lookup. Per-cuisine evaluation is critical because training data bias can cause 15-50% calorie errors for non-Western cuisines (research blocker).

Output: Three trained YOLO26-N model checkpoints in `training/runs/` and per-cuisine accuracy reports.
</objective>

<execution_context>
@/Users/jting/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jting/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-food-detection-foundation/01-RESEARCH.md
@.planning/phases/01-food-detection-foundation/01-CONTEXT.md
@.planning/phases/01-food-detection-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Train binary food/not-food classifier and dish classification model</name>
  <files>
    training/train_binary.py
    training/train_classify.py
  </files>
  <action>
Train the two classification models using YOLO26-N-cls:

1. Create `training/train_binary.py`:
   - Load pretrained YOLO26 nano classification model: `YOLO("yolo26n-cls.pt")`
   - Fine-tune on the binary food/not-food dataset:
     ```python
     results = model.train(
         data="training/datasets/food-binary/",
         epochs=30,           # Binary classification converges fast
         imgsz=224,
         batch=64,
         device="mps",        # Apple Silicon; fallback to "cpu"
         patience=10,         # Early stopping
         augment=True,
         project="training/runs/classify",
         name="food-binary",
     )
     ```
   - After training, validate and print accuracy:
     ```python
     metrics = model.val()
     print(f"Binary classifier - Top-1: {metrics.top1:.3f}")
     ```
   - Save the best model path for later use
   - Target: >90% accuracy on food/not-food (this is a trivial binary task for YOLO)

2. Create `training/train_classify.py`:
   - Load pretrained YOLO26 nano classification model: `YOLO("yolo26n-cls.pt")`
   - Fine-tune on the merged Food-101 + ISIA-500 classification dataset:
     ```python
     results = model.train(
         data="training/datasets/food-classification/",
         epochs=50,
         imgsz=224,
         batch=64,
         device="mps",
         patience=20,
         augment=True,
         project="training/runs/classify",
         name="food-dish",
     )
     ```
   - After training, validate:
     ```python
     metrics = model.val()
     print(f"Dish classifier - Top-1: {metrics.top1:.3f}, Top-5: {metrics.top5:.3f}")
     ```
   - Target: >70% Top-1 accuracy (Food-101 SOTA is ~95% but with much larger models; nano model will be lower)
   - Save best model checkpoint path

Both scripts should:
- Check for MPS/CUDA availability and fall back gracefully to CPU
- Print training configuration before starting
- Save training metrics to a JSON file alongside the model for later comparison
- Handle KeyboardInterrupt gracefully (save current checkpoint)
  </action>
  <verify>
- `python training/train_binary.py` completes training (or is already trained) and `training/runs/classify/food-binary/weights/best.pt` exists
- `python training/train_classify.py` completes training and `training/runs/classify/food-dish/weights/best.pt` exists
- Binary classifier achieves >90% Top-1 accuracy on validation set
- Dish classifier achieves >50% Top-1 accuracy on validation set (lower bar at this stage; will improve with more data)
  </verify>
  <done>
- Binary food/not-food classifier trained with >90% accuracy
- Dish classification model trained with best achievable Top-1/Top-5 accuracy
- Both model checkpoints saved to training/runs/classify/
- Training metrics saved as JSON files alongside model weights
  </done>
</task>

<task type="auto">
  <name>Task 2: Train YOLO26-N food detector and run per-cuisine evaluation</name>
  <files>
    training/train_detect.py
    training/evaluate/eval_detection.py
    training/evaluate/eval_classification.py
  </files>
  <action>
Train the detection model and create comprehensive per-cuisine evaluation:

1. Create `training/train_detect.py`:
   - Load pretrained YOLO26 nano detection model: `YOLO("yolo26n.pt")`
   - Fine-tune on the merged detection dataset (auto-labeled + Roboflow):
     ```python
     results = model.train(
         data="training/configs/food-detect.yaml",
         epochs=100,
         imgsz=640,
         batch=16,           # Detection needs more memory; lower batch size
         device="mps",
         patience=20,
         augment=True,
         project="training/runs/detect",
         name="food-detect",
     )
     ```
   - After training, validate:
     ```python
     metrics = model.val()
     print(f"Detection - mAP@0.5: {metrics.box.map50:.3f}")
     print(f"Detection - mAP@0.5:0.95: {metrics.box.map:.3f}")
     ```
   - Target: >60% mAP@0.5 (realistic for fine-tuned nano model on diverse food)
   - Detection training takes longer than classification; set patience=20 for early stopping

2. Create `training/evaluate/eval_detection.py`:
   - Load trained detection model from `training/runs/detect/food-detect/weights/best.pt`
   - Load the cuisine mapping (reuse or import from `audit_cuisines.py`)
   - Run evaluation on test set, grouping results by cuisine:
     ```python
     # For each image in test set:
     #   - Run detection
     #   - Map detected class to cuisine
     #   - Track TP/FP/FN per cuisine
     # Calculate per-cuisine mAP@0.5
     ```
   - Output a per-cuisine report:
     ```
     Cuisine       | Images | Detections | mAP@0.5 | mAP@0.5:0.95
     --------------|--------|------------|---------|-------------
     Western       |  5000  |    6234    |  0.75   |    0.52
     Chinese       |   800  |    1023    |  0.62   |    0.41
     Japanese      |   600  |     789    |  0.68   |    0.45
     ...
     ```
   - Flag any cuisine with mAP@0.5 < 0.50 as needing more training data
   - Save report to `training/evaluate/detection_cuisine_report.txt`

3. Create `training/evaluate/eval_classification.py`:
   - Load trained classification model from `training/runs/classify/food-dish/weights/best.pt`
   - Run evaluation on test set, grouping results by cuisine:
   - Calculate per-cuisine Top-1 and Top-5 accuracy
   - Generate confusion matrix for top-20 most confused class pairs
   - Output per-cuisine report (same format as detection report)
   - Flag any cuisine with Top-1 accuracy < 50%
   - Save report to `training/evaluate/classification_cuisine_report.txt`
   - Save confusion matrix data to `training/evaluate/confusion_matrix.json`

Both evaluation scripts should:
- Support `--model-path` argument to evaluate different checkpoints
- Output results to both stdout and file
- Be rerunnable without re-training
  </action>
  <verify>
- `python training/train_detect.py` completes and `training/runs/detect/food-detect/weights/best.pt` exists
- `python training/evaluate/eval_detection.py` produces `training/evaluate/detection_cuisine_report.txt` with per-cuisine mAP breakdown
- `python training/evaluate/eval_classification.py` produces `training/evaluate/classification_cuisine_report.txt` and `confusion_matrix.json`
- Detection model achieves >50% mAP@0.5 overall
- Per-cuisine reports cover all 6 priority cuisines
  </verify>
  <done>
- Detection model trained with reported mAP@0.5 and mAP@0.5:0.95
- Per-cuisine detection report identifies cuisines below threshold
- Per-cuisine classification report with Top-1/Top-5 accuracy
- Confusion matrix reveals most-confused class pairs for targeted improvement
- All three YOLO26 model checkpoints are saved and ready for export
  </done>
</task>

</tasks>

<verification>
- Three model checkpoints exist: food-binary, food-dish, food-detect
- Binary classifier: >90% accuracy
- Detection model: mAP reported with per-cuisine breakdown
- Classification model: Top-1/Top-5 accuracy reported with per-cuisine breakdown
- No cuisine has 0% coverage (all priority cuisines represented in evaluation)
</verification>

<success_criteria>
- All three YOLO26-N models trained to convergence (or early-stopped)
- Per-cuisine evaluation reports generated for both detection and classification
- Detection mAP@0.5 and classification Top-1 accuracy numbers recorded for go/no-go comparison
- Cuisine gaps identified and documented for potential data augmentation
</success_criteria>

<output>
After completion, create `.planning/phases/01-food-detection-foundation/01-03-SUMMARY.md`
</output>
